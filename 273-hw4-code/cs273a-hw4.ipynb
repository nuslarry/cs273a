{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import math as math\n",
    "entropy_y = 0.6*math.log(10/6.0,2) + 0.4*math.log(10/4.0,2)\n",
    "print(\"entropy H(y)=\",entropy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 information gain \n",
    "entropy_1_1 = (3.0/6)*math.log(6.0/3,2) + (3.0/6)*math.log(6.0/3,2)\n",
    "entropy_1_0 = (3.0/4)*math.log(4.0/3,2) + (1.0/4)*math.log(4.0,2)\n",
    "information_gain_1 = (6.0/10)*(entropy_y - entropy_1_1) + (4.0/10)*(entropy_y - entropy_1_0)\n",
    "print('Information gain for feature 1:, %0.4f' %(information_gain_1))\n",
    "\n",
    "# x2 information gain \n",
    "ent_2_1 = (5.0/5)*math.log(5.0/5,2)\n",
    "ent_2_0 = (4.0/5)*math.log(5.0/4,2) + (1.0/5)*math.log(5.0,2)\n",
    "information_gain_2 = (5.0/10)*(entropy_y - ent_2_1) + (5.0/10)*(entropy_y - ent_2_0)\n",
    "print('Information gain for feature 2:, %0.4f' %(information_gain_2))\n",
    "\n",
    "# x3 information gain \n",
    "ent_3_1 = (3.0/7)*math.log(7.0/3,2) + (4.0/7)*math.log(7.0/4,2)\n",
    "ent_3_0 = (1.0/3)*math.log(3.0,2) + (2.0/3)*math.log(3.0/2,2)\n",
    "information_gain_3 = (7.0/10)*(entropy_y - ent_3_1) + (3.0/10)*(entropy_y - ent_3_0)\n",
    "print('Information gain for feature 3:, %0.4f' %(information_gain_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4 information gain \n",
    "ent_4_1 = (2.0/7)*math.log(7.0/2,2) + (5.0/7)*math.log(7.0/5,2)\n",
    "ent_4_0 = (2.0/3)*math.log(3.0/2,2) + (1.0/3)*math.log(3.0,2)\n",
    "information_gain_4 = (7.0/10)*(entropy_y - ent_4_1) + (3.0/10)*(entropy_y - ent_4_0)\n",
    "print('Information gain for feature 4:, %0.4f' %(information_gain_4))\n",
    "\n",
    "# x5 information gain \n",
    "ent_5_1 = (1.0/3)*math.log(3.0,2) + (2.0/3)*math.log(3.0/2,2)\n",
    "ent_5_0 = (3.0/7)*math.log(7.0/3,2) + (4.0/7)*math.log(7.0/4,2)\n",
    "information_gain_5 = (3.0/10)*(entropy_y - ent_5_1) + (7.0/10)*(entropy_y - ent_5_0)\n",
    "print('Information gain for feature 5:, %0.4f' %(information_gain_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should split on variable 2 for the root node of the decision tree since it has the highest Information gain 0.6100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.3:\n",
    "<img src=\"q1.3.png\" alt=\"Drawing\" style=\"width:550px;height:340px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "yt = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "xt,yt = ml.shuffleData(xt,yt)\n",
    "for i in range(X.shape[1]):\n",
    "    print('minimum of x%d:, %0.4f' %(i,min(xt[:,0])))\n",
    "    print('maximum of x%d:, %0.4f' %(i,max(xt[:,0])))\n",
    "    print('mean of x%d:, %0.4f' %(i,np.mean(xt[:,0])))\n",
    "    print('mean of x%d:, %0.4f' %(i,np.var(xt[:,0])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gg\")\n",
    "xt_0_10000 = xt[0:10000]\n",
    "yt_0_10000 = yt[0:10000]\n",
    "\n",
    "xv_10000_20000 = xt[10000:20000]\n",
    "yv_10000_20000 = yt[20000:100000]\n",
    "\n",
    "dt = ml.dtree.treeClassify(xt_0_10000, yt_0_10000, maxDepth = 50)\n",
    "\n",
    "\n",
    "yt_0_10000_hat = dt.predict(xt_0_10000))\n",
    "yv_0_10000_hat = arr(dt.predict(xv_10000_20000))\n",
    "\n",
    "# Yt_true = arr(Yt)\n",
    "# Yv_true = arr(Yv)\n",
    "\n",
    "# print('Training Error:, %0.4f' %(np.mean(ythat.reshape(Yt_true.shape) != Yt_true)))\n",
    "# print('Validation Error:, %0.4f' %(np.mean(yvhat.reshape(Yv_true.shape) != Yv_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "kk=[1,2,3]\n",
    "print(np.sum(kk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
